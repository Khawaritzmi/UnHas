{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# http://tau-data.id/unhas/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img alt=\"\" src=\"images/0_Cover.jpg\"/></center> \n",
    "\n",
    "## <center><font color=\"blue\">Modul 04: Topic Modelling</font></center>\n",
    "<b><center>(C) Taufik Sutanto - 2019</center>\n",
    "<center>tau-data Indonesia ~ https://tau-data.id ~ taufik@tau-data.id</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center><font color=\"blue\">Topic Modelling</font></center>\n",
    "<img alt=\"\" src=\"images/PDS_logo.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <font color=\"blue\">Workshop Schedule</font>\n",
    "\n",
    "<center><img alt=\"\" src=\"images/Outline.jpeg\"/></center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing Modules for Google Colab\n",
    "!wget https://raw.githubusercontent.com/taufikedys/UnHas/master/taudata.py\n",
    "!mkdir data\n",
    "!wget -P data/ https://raw.githubusercontent.com/taufikedys/UnHas/master/data/Tweets.json\n",
    "!wget -P data/ https://raw.githubusercontent.com/taufikedys/UnHas/master/data/dataTweet.txt\n",
    "!wget -P data/ https://raw.githubusercontent.com/taufikedys/UnHas/master/data/slang.dic\n",
    "!wget -P data/ https://raw.githubusercontent.com/taufikedys/UnHas/master/data/stopwords_id.txt\n",
    "!wget -P data/ https://raw.githubusercontent.com/taufikedys/UnHas/master/data/stopwords_en.txt\n",
    "!wget -P data/ https://raw.githubusercontent.com/taufikedys/UnHas/master/data/all_indo_man_tag_corpus_model.crf.tagger\n",
    "!wget -P data/ https://raw.githubusercontent.com/taufikedys/UnHas/master/data/kata_dasar.txt\n",
    "!pip install unidecode\n",
    "!pip install pyLDAvis\n",
    "!pip install textblob\n",
    "!pip install sastrawi\n",
    "!pip install twython\n",
    "!pip install tweepy\n",
    "!pip install spacy\n",
    "!pip install python-crfsuite\n",
    "!python -m spacy download en\n",
    "!python -m spacy download xx\n",
    "!python -m spacy download en_core_web_sm\n",
    "import nltk\n",
    "nltk.download('popular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Modules untuk Notebook ini\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "import taudata as tau, itertools, re, pickle, pyLDAvis, pyLDAvis.sklearn, spacy, nltk, urllib.request\n",
    "import time, numpy as np, matplotlib.pyplot as plt, networkx as nx, pandas as pd, seaborn as sns \n",
    "from matplotlib.colors import ListedColormap\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from nltk.tag import CRFTagger\n",
    "from gensim.models import Phrases\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec, FastText\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "random_state = 170"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <font color=\"blue\">Outline Topic Modelling :</font>\n",
    "* Pendahuluan Topic Modelling\n",
    "* Soft Clustering (Topic Modelling): LDA dan NMF\n",
    "* Visualisasi dan Interpretasi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Ketika mengolah dokumen (file dalam bentuk teks), harapan kita seperti ini:</h3>\n",
    "\n",
    "<img alt=\"\" src=\"images/4_harapan_LSA.png\" style=\"height:99px; width:198px\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Namun kita sudah bahas kemarin kenyataannya seperti ini:</h3>\n",
    "\n",
    "<p><img alt=\"\" src=\"images/4_kenyataan_LSA.png\" style=\"height:183px; width:182px\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Topic-Modelling-1-:-Latent-Dirichlet-Allocation\">Topic Modelling 1 : Latent Dirichlet Allocation</h2>\n",
    "\n",
    "<p><img alt=\"\" src=\"images/4_Document_to_Topics.png\" style=\"height: 300px ; width: 582px\" /></p>\n",
    "\n",
    "<p><strong><big>Tapi bukan seperti klasifikasi dan bukan berarti kata-kata Sport, Technology, dan Entertainment dominan di kategori-kategori tersebut. Topic modelling lebih ke soft-clustering, dimana suatu dokumen dimasukkan ke dalam beberapa cluster (topic) sekaligus. Adapun nama &quot;topic/cluster&quot;-nya di interpretasi dari kata-kata yang ada didalamnya.</big></strong></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"\" src=\"images/4_LDA vs LDA.JPG\" style=\"height:400px; width:606px\" /></p>\n",
    "[<a href=\"http://chdoig.github.io/pytexas2015-topic-modeling/\" target=\"_blank\">Sumber gambar ini dan beberapa gambar selanjutnya</a>]</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"\" src=\"images/4_definisi topic model.JPG\" style=\"height:350px; width:809px\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"\" src=\"images/4_inti_LDA.JPG\" style=\"height:500px; width:785px\" /></p>\n",
    "Penjelasan intuitif yang baik: https://medium.com/@lettier/how-does-lda-work-ill-explain-using-emoji-108abf40fa7d "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Evaluasi LDA?</h3>\n",
    "\n",
    "<p><img alt=\"\" src=\"images/4_Evaluasi_LDA.jpg\" style=\"height:400px; width:888px\" /></p>\n",
    "[Cara lain: http://mimno.infosci.cornell.edu/slides/details.pdf]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"\" src=\"images/4_LDA Pipeline.JPG\" style=\"height:300px; width:663px\" /></p>\n",
    "* Modifikasi dapat dilakukan dengan \"pos tags\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopId, lemmaId = tau.LoadStopWords(lang='id') \n",
    "print('Loading Data  ... ')\n",
    "T2 = tau.loadTweets(file='data/Tweets.json')\n",
    "D = [t['full_text'] for t in T2] # Tweet hasil crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading Slang, stopwords, dan fungsi lemma ... ')\n",
    "\n",
    "slangFixId = tau.loadCorpus(file = 'data/slang.dic', sep=':')\n",
    "stopId, lemmaId = tau.LoadStopWords(lang='id') # kita akan menggunakan stopwords dan Lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cleaning Data ... ')\n",
    "data = []\n",
    "for i, d in tqdm(enumerate(D)):\n",
    "    doc = tau.cleanText(d, fix=slangFixId, lemma=lemmaId, stops = set(stopId))\n",
    "    data.append(doc)\n",
    "print(data[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kita mulai dengan membuat VSM-nya\n",
    "# kita gunakan perintah yang ada di Segmen sebelumnya \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "tf_vectorizer = CountVectorizer()\n",
    "\n",
    "tf = tf_vectorizer.fit_transform(data)\n",
    "tf_terms = tf_vectorizer.get_feature_names()\n",
    "# Mengapa tf bukan tfidf?\n",
    "# Blei, D. M., Ng, A. Y., & Jordan, M. I. (2003). Latent dirichlet allocation. Journal of machine Learning research, 3(Jan), 993-1022.\n",
    "# Bisa di tamahkan dengan Frequency filtering \"Max_df\" dan \"Min_df\"\n",
    "\n",
    "tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dilanjutkan dengan membentuk model LDA-nya\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "\n",
    "n_topics = 3\n",
    "lda = LDA(n_components=n_topics, learning_method='batch', random_state=0).fit(tf)   \n",
    "lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melihat Topik-topiknya\n",
    "vsm_topics = lda.transform(tf)\n",
    "print(vsm_topics.shape)\n",
    "vsm_topics\n",
    "# Ukuran kolom = #Topics ==> Dimension Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seandainya diasumsikan 1 dokumen hanya 1 topic dengan nilai skor topic terbesar\n",
    "doc_topic =  [a.argmax()+1 for a in tqdm(vsm_topics)] # topic of docs\n",
    "doc_topic[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mari kita plot\n",
    "plot = sns.countplot(doc_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mari kita coba maknai masing-masing topic ini\n",
    "Top_Words = 15\n",
    "print('Printing top {0} Topics, with top {1} Words:'.format(n_topics, Top_Words))\n",
    "tau.print_Topics(lda, tf_terms, n_topics, Top_Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# Mari kita Plot, supaya lebih jelas\n",
    "# Catatan, bergantung dari laptop yang digunakan, image terkadang cukup lama untuk muncul.\n",
    "import pyLDAvis, pyLDAvis.sklearn; pyLDAvis.enable_notebook()\n",
    "\n",
    "pyLDAvis.sklearn.prepare(lda, tf, tf_vectorizer)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagaimana jika kita ingin menggunakan semi-supervised (guided) LDA?\n",
    "https://medium.freecodecamp.org/how-we-changed-unsupervised-lda-to-semi-supervised-guidedlda-e36a95f3a164 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagaimana melakukan Post-Tag sebelum Topic Modelling?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.id import Indonesian\n",
    "from nltk.tag import CRFTagger\n",
    "nlp_id = Indonesian()  # Language Model\n",
    "ct = CRFTagger()\n",
    "ct.set_model_file('data/all_indo_man_tag_corpus_model.crf.tagger')\n",
    "\n",
    "def NLPfilter(t, filters):\n",
    "    tokens = nlp_id(t)\n",
    "    tokens = [str(k) for k in tokens if len(k)>2]\n",
    "    hasil = ct.tag_sents([tokens])\n",
    "    return [k[0] for k in hasil[0] if k[1] in filters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = set(['NN', 'NNP', 'NNS', 'NNPS', 'JJ'])\n",
    "\n",
    "for i, d in tqdm(enumerate(data)):\n",
    "    data[i] = NLPfilter(d,filters)\n",
    "\n",
    "' '.join(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluasi: Bagaimana mendapatkan parameter Optimal Topic Modelling?\n",
    "\n",
    "**Beberapa catatan penting**:\n",
    "1. Hati-hati Struktur Data, untuk melakukan evaluasi Topic Modelling struktur data yang digunakan mirip dengan Word Embedding.\n",
    "2. Kita akan melakukan cross-validasi dan N-Gram\n",
    "3. Ada berbagai metric evaluasi https://radimrehurek.com/gensim/models/coherencemodel.html\n",
    "4. Referensi paper: http://svn.aksw.org/papers/2015/WSDM_Topic_Evaluation/public.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_t = Phrases(data, min_count=10)\n",
    "trigram_t = Phrases(bigram_t[data])\n",
    "for idx, d in enumerate(data):\n",
    "    for token in bigram_t[d]:\n",
    "        if '_' in token:# Token is a bigram, add to document.\n",
    "            data[idx].append(token)\n",
    "    for token in trigram_t[d]:\n",
    "        if '_' in token:# Token is a bigram, add to document.\n",
    "            data[idx].append(token)\n",
    "\n",
    "# Create a dictionary representation of the documents.\n",
    "# Remove rare & common tokens\n",
    "dictionary_t = Dictionary(data)\n",
    "dictionary_t.filter_extremes(no_below=10, no_above=0.2)\n",
    "#Create dictionary and corpus required for Topic Modeling\n",
    "corpus_t = [dictionary_t.doc2bow(doc) for doc in data]\n",
    "print('Number of unique tokens: %d' % len(dictionary_t))\n",
    "print('Number of documents: %d' % len(corpus_t))\n",
    "print(corpus_t[:1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, coherence='c_v', start=2, step=3):\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in tqdm(range(start, limit, step)):\n",
    "        model=LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence=coherence)\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caution cell berikut ini membutuhkan waktu yang cukup signifikan untuk selesai, karena selain LDA *computationally expensive* loopingnya juga melakukan Cross-validasi di setiap jumlah topik *k*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start, step, limit = 2, 1, 10 # Ganti dengan berapa banyak Topic yang ingin di hitung/explore\n",
    "coh_t, kCV = [], 3 # hati-hati sangat lambat karena cross validation pada metode yang memang tidak efisien (LDA)\n",
    "\n",
    "for i in tqdm(range(kCV)):\n",
    "    model_list, c = compute_coherence_values(dictionary=dictionary_t, corpus=corpus_t, texts=data, start=start, limit=limit, step=step)\n",
    "    coh_t.append(c)\n",
    "    \n",
    "coherence_t = np.mean(np.array(coh_t), axis=0)\n",
    "'Done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show graph\n",
    "x = range(start, limit, step)\n",
    "plt.figure(figsize=(12,10))\n",
    "for c in coh_t:\n",
    "    plt.plot(x, c, '--', color = 'lawngreen', linewidth = 2)\n",
    "plt.plot(x, coherence_t, '-', color = 'black', linewidth = 5)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referensi Pilihan:\n",
    "\n",
    "* perhitungan Manual Topic Modelling LDA: http://brooksandrew.github.io/simpleblog/articles/latent-dirichlet-allocation-under-the-hood/\n",
    "* http://mimno.infosci.cornell.edu/slides/details.pdf\n",
    "* https://datascienceplus.com/evaluation-of-topic-modeling-topic-coherence/\n",
    "* http://www.umiacs.umd.edu/~jbg/docs/nips2009-rtl.pdf\n",
    "* http://radimrehurek.com/topic_modeling_tutorial/2%20-%20Topic%20Modeling.html\n",
    "* Penjelasan intuitif yang baik: https://medium.com/@lettier/how-does-lda-work-ill-explain-using-emoji-108abf40fa7d \n",
    "* inconjunction dengan interactive program berikut: https://lettier.com/projects/lda-topic-modeling/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>&nbsp;</p>\n",
    "\n",
    "<h3 id=\"Non-Negative-Matrix-Decomposition-(NMF)\">Non-Negative Matrix Decomposition (NMF)</h3>\n",
    "\n",
    "<p><img alt=\"\" src=\"images/4_NMF.jpg\" style=\"height: 349px; width: 600px;\" /> [image source: <a href=\"https://www.slideshare.net/SebastianRuder/dynamic-topic-modeling-via-nonnegative-matrix-factorization-dr-derek-greene]\">https://www.slideshare.net/SebastianRuder/dynamic-topic-modeling-via-nonnegative-matrix-factorization-dr-derek-greene]</a></p>\n",
    "\n",
    "<p>&nbsp;</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"Tujuan-NMF:\">Tujuan NMF:</h3>\n",
    "\n",
    "<p><img alt=\"\" src=\"images/4_NMF_Goal.JPG\" style=\"height: 363px; width: 600px;\" /></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langsung Aplikasi-nya\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "data = []\n",
    "for i, d in tqdm(enumerate(D)):\n",
    "    doc = tau.cleanText(d, fix=slangFixId, lemma=lemmaId, stops = set(stopId))\n",
    "    data.append(doc)\n",
    "\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf = tfidf_vectorizer.fit_transform(data)\n",
    "nmf_model = NMF(n_components = 3, random_state=0)\n",
    "nmf = nmf_model.fit(tfidf)\n",
    "\n",
    "print(\"\\nTopics in NMF model:\")\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "tau.print_Topics(nmf, tfidf_feature_names, n_topics, Top_Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sama seperti LDA kita bisa melihat distribusi topic setiap dokumen\n",
    "vsm_topics = nmf.transform(tfidf)\n",
    "vsm_topics[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seandainya diasumsikan 1 dokumen hanya 1 topic dengan nilai skor topic terbesar\n",
    "doc_topic =  [a.argmax()+1 for a in tqdm(vsm_topics)] # topic of docs\n",
    "print('In total there are {0} major topics, distributed as follows'.format(len(set(doc_topic))))\n",
    "sns.countplot(doc_topic)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perkalian Matrix-nya (Aljabar Linear)\n",
    "W = nmf_model.fit_transform(tfidf)\n",
    "H = nmf_model.components_\n",
    "terms = tfidf_vectorizer.get_feature_names()\n",
    "print(W.shape, H.shape, len(terms))\n",
    "#print(terms[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latihan :\n",
    "\n",
    "* Load data data tweet dengan isu berbeda, \"misal\" **revitalisasi monas, banjir, atau isu terkini lainnya**\n",
    "* Lakukan preprocessing (termasuk lemma) dan pos tag (ambil hanya noun saja)\n",
    "* Bandingkan hasil topic dari LDA, dan NMF dari data tersebut.\n",
    "* Apakah hasilnya sudah baik?\n",
    "* Buat visualisasi pyLDAvis-nya dan analisa lebih lanjut.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\"> End of Module 04\n",
    "\n",
    "<hr />\n",
    "<p><img alt=\"\" src=\"images/1_meme.jpg\" /></p>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
